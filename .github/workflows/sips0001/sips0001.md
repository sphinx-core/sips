# SphinxHash

> Authors : C. Kusuma
> 
> Licence : MIT

## Overview

The idea of **[SpinxHash](https://github.com/sphinx-core/go/tree/main/src/spxhash)** to combinied SHA and SHAKE into a single hash output is inspired by the early days of cryptography and secure communication protocols, particularly **[TLS and SSL](https://www.cryptoplexity.informatik.tu-darmstadt.de/media/crypt/publications_1/fischlinssl-combiners2010.pdf)**, back in 1995. During the transition from MD5 to SHA-1, the cryptographic community witnessed how combining different hash functions could provide stronger security. 

Before 1995, the cryptographic world relied heavily on the MD family of hash functions. However, MD5 was eventually deemed insecure, leading the **[N.S.A](https://en.wikipedia.org/wiki/SHA-1)** to create SHA-1. But an interesting development occurred with TLS and SSL, which decided to combine hash functions for better security. This combined approach turned out to be stronger than relying on a single hash function.

In the current era, as we transition from traditional cryptographic primitives to Post-Quantum Cryptography (PQC), there is skepticism surrounding the use of single hash algorithms like SHA2 or SHA3. We believe the answer lies in combining them, leveraging their individual strengths to create a more robust and secure single hash output.

## Motivation

### 1. Grover's Algorithm and Pre-Image Attacks
1.1. What Grover’s Algorithm Does:
* [Grover's Algorithm](https://learning.quantum.ibm.com/course/fundamentals-of-quantum-algorithms/grovers-algorithm) gives a quadratic speedup for unstructured search problems, like pre-image attacks on cryptographic hash functions (CHFs).
For a hash function with output size 𝑛, a classical brute-force pre-image attack requires $𝑂(2^𝑛)$ operations.
Grover reduces this to $𝑂(2^𝑛/2)$.

1.2. Impact on Security:
* In practical terms, Grover’s algorithm effectively halves the security of a hash function against pre-image attacks.
Example: A 256-bit CHF (like SHA-256) would be reduced to the security level of a 128-bit hash function under a quantum attack using Grover's algorithm. Even with this reduction, performing $2^128$ operations for a Grover-assisted attack remains infeasible with current and near-future quantum computing technology.


1.3. Speedup for Collision Attacks:
* Grover's algorithm does not provide a significant speedup for collision attacks on hash functions like SHA-256. The most efficient method for finding collisions remains the birthday attack, which has a time complexity of $O(2^n/2)$, where $n$ is the hash output size. Grover's algorithm, while accelerating search algorithms, does not fundamentally alter the complexity of the birthday attack.

### 2. BHT Algorithm and Hash Collisions

2.1. What the BHT Algorithm Does:
* Proposed by Brassard, Høyer, and Tapp in 1997, the [BHT Algorithm](https://en.wikipedia.org/wiki/BHT_algorithm) combines the classical birthday attack with Grover's search to theoretically achieve a collision attack with time complexity $𝑂(2^𝑛/3)$

2.2. Dependency on Quantum RAM (qRAM):
* The $𝑂(2^𝑛/3)$ scaling assumes the existence of [Quantum RAM (qRAM)](https://qmunity.thequantuminsider.com/2024/04/29/quantum-ram-new-milestone/), which currently does not exist. Without QRAM, the achievable scaling is only $𝑂~(2^2𝑛/5)$, which is not much better than the classical birthday attack's 
$𝑂(2^𝑛/2)$.

## Key Points

**1. Pre-image resistance:** SHA-256 has 256 bits of security classically. Under [Grover's Algorithm](https://learning.quantum.ibm.com/course/fundamentals-of-quantum-algorithms/grovers-algorithm), this reduces to 128 bits.

**2. Collision resistance:** SHA-256 provides 128 bits of security (birthday attack). Quantum algorithms do not reduce this further.

**3. BHT collision attack:** The improvement to $𝑂(2^𝑛/3)$ is theoretical and requires [Quantum RAM (qRAM)](https://qmunity.thequantuminsider.com/2024/04/29/quantum-ram-new-milestone/).


## Putting SHA and SHAKE together
**Independent Hash Functions:**  
In our implementation, the `SphinxHash` function leverages **SHA-512/256** and **SHAKE-256** to enhance security. Since both algorithms are used independently within the `hashData` function, an attacker would need to compromise both hash functions to break the system.  

### SHA Specifications  

| Algorithm      | Message Size (bits) | Block Size (bits) | Word Size (bits) | Message Digest Size (bits) |
|----------------|----------------------|-------------------|------------------|----------------------------|
| SHA-1          | < 2⁶⁴               | 512               | 32               | 160                        |
| SHA-224        | < 2⁶⁴               | 512               | 32               | 224                        |
| SHA-256        | < 2⁶⁴               | 512               | 32               | 256                        |
| SHA-384        | < 2¹²⁸              | 1024              | 64               | 384                        |
| SHA-512        | < 2¹²⁸              | 1024              | 64               | 512                        |
| SHA-512/224    | < 2¹²⁸              | 1024              | 64               | 224                        |
| SHA-512/256    | < 2¹²⁸              | 1024              | 64               | 256                        |

### SHA-512/256  

In this project, we have chosen **SHA-512/256** as a primary hash function because of its robust design and strong resistance to both classical and quantum computing attacks. SHA-512/256 uses a $2^{128}$ internal state, operates with a 1024-bit block size, and generates a 256-bit message digest. Its design strikes a balance between security and performance, making it ideal for high-stakes cryptographic applications.  


### Security Comparison

| Function        | Output Size | Collision | 2nd Preimage | Preimage |
|-----------------|-------------|-----------|--------------|----------|
| SHA-1           | 160         | 160       | 160          | 160–L($M$) |
| SHA-224         | 224         | 224       | 224          | min(224, 256–L($M$)) |
| SHA-512/224     | 224         | 224       | 224          | 224      |
| SHA-256         | 256         | 256       | 256          | 256–L($M$) |
| SHA-512/256     | 256         | 256       | 256          | 256      |
| SHA-384         | 384         | 384       | 384          | 384      |
| SHA-512         | 512         | 512       | 512          | 512–L($M$) |
| SHA3-224        | 224         | 224       | 224          | 224      |
| SHA3-256        | 256         | 256       | 256          | 256      |
| SHA3-384        | 384         | 384       | 384          | 384      |
| SHA3-512        | 512         | 512       | 512          | 512      |
| SHAKE128        | $d$           | min($d$/2, 128) | ≥ min($d$, 128)  | min($d$, 128) |
| SHAKE256        | $d$           | min($d$/2, 256) | ≥ min($d$, 256)  | min($d$, 256) |


### SHAKE-256 and its Relation to SHA-512/256  

**SHAKE-256**, part of the SHA-3 family, is a versatile, extendable-output hash function (XOF). When used in combination with SHA-512/256, SHAKE-256 is configured to output a 256-bit digest, ensuring consistency with the internal state size of SHA-512/256. This alignment creates a harmonious integration where both algorithms effectively reinforce each other's security properties.  

**Combined Security Strength:**  
- **SHA-512/256:** Its security is based on its extended internal state size and pre-image resistance of 128 bits (when accounting for Grover's algorithm).  
- **SHAKE-256:** When configured for a 256-bit output, it similarly achieves 128 bits of effective security against quantum attacks.  

The combination of **SHA-512/256** and **SHAKE-256** offers a resilient hashing mechanism designed to withstand evolving cryptographic threats. By aligning SHAKE-256 with the internal state properties of SHA-512/256, we ensure a secure, efficient, and future-proof hashing strategy.  



## Summary
The overall security of SphinxHash is determined by the most vulnerable hash function. If an attacker can efficiently target either SHA-256 or SHAKE-256, they can reduce the security of the combined hash to approximately 128 bits.


## Structure
Example run the code:

```bash
package main

import (
	"fmt"
	"log"

	spxhash "github.com/sphinx-core/sphinx-core/src/spxhash/hash"
)

func main() {
	// Define three different messages to hash
	messages := [][]byte{
		[]byte("Hello, SphinxHash!"),
		[]byte("Hello, Sphinxhash!"),
		[]byte("Hash functions are fascinating."),
	}

	// Iterate over the messages and compute their hashes
	for i, data := range messages {
		fmt.Printf("\nMessage %d: %s\n", i+1, data)

		// Create a new SphinxHash instance for each message
		sphinx := spxhash.NewSphinxHash(256, []byte{})

		// Write data to the SphinxHash instance
		n, err := sphinx.Write(data)
		if err != nil {
			log.Fatalf("Error writing data for message %d: %v", i+1, err)
		}
		fmt.Printf("Wrote %d bytes to the hash.\n", n)

		// Retrieve the computed hash
		hash := sphinx.Sum(nil) // Sum with nil appends the hash to an empty slice
		fmt.Printf("Computed hash: %x\n", hash)

		// Check the length of the computed hash
		if len(hash) != 32 {
			fmt.Printf("Warning: Computed hash for message %d is not 256 bits.\n", i+1)
		} else {
			fmt.Printf("Computed hash for message %d is 256 bits.\n", i+1)
		}

		// Optional: You can check cache usage by trying to get the hash again
		cachedHash := sphinx.GetHash(data)
		if cachedHash != nil {
			fmt.Printf("Cached hash: %x\n", cachedHash)
		} else {
			fmt.Println("No cached hash found.")
		}
	}
}
```
**The results :**

```bash
* Message 1: Hello, SphinxHash!
* Wrote 18 bytes to the hash.
* Computed hash: `c7790a04c8553ba17a68737c86c5c2818614b400c29010b5b30ca1ae7b8bf445`
* Computed hash for message 1 is 256 bits.
* Cached hash: `c7790a04c8553ba17a68737c86c5c2818614b400c29010b5b30ca1ae7b8bf445`

* Message 2: Hello, Sphinxhash!
* Wrote 18 bytes to the hash.
* Computed hash: `5b93e50e030bc7acf12e1ba5a942f720e3c5f504a23ea597f14c607b99d763fe`
* Computed hash for message 2 is 256 bits.
* Cached hash: `5b93e50e030bc7acf12e1ba5a942f720e3c5f504a23ea597f14c607b99d763fe`

* Message 3: Hash functions are fascinating.
* Wrote 31 bytes to the hash.
* Computed hash: `7c9501b68d6aa8930cb91bd7c3b2730e82a929182c9c35302460e95a30d7c025`
* Computed hash for message 3 is 256 bits.
* Cached hash: `7c9501b68d6aa8930cb91bd7c3b2730e82a929182c9c35302460e95a30d7c025`

[Done] exited with code=0 in 2.033 seconds
```

**The code run on hardware spesifications:**
* Processor : 2,6 GHz Quad-Core Intel Core i7
* Memory : 16 GB 2133 MHz LPDDR3


**1. LRU Cache**

The LRUCache structure maintains a fixed-size cache of recently accessed items, enabling quick retrieval and eviction of the least recently used items when the cache reaches its capacity.

The LRU cache mechanism is implemented to optimize hash retrieval. The cache maintains a mapping of keys to their corresponding values, ensuring efficient access and eviction.


Key Functions:

* `Get(key uint64)`: Retrieves the value associated with a given key, moving the accessed node to the front of the cache.

* `Put(key uint64, value []byte)`: Inserts a new value into the cache or updates an existing one, evicting the least recently used item if necessary.

* `evict()`: Removes the least recently used item from the cache.

* `moveToFront(node *Node)`: Moves a node to the front of the linked list representing the cache.


**2. SphinxHash**

The SphinxHash struct encapsulates the core hashing functionality, allowing users to hash data using a combination of SHA2 and SHAKE algorithms. It leverages salt and Argon2 for key stretching, enhancing security by providing resistance against brute-force attacks.

Key Functions:

* `Write(p []byte)`: Appends data to be hashed.

* `Sum(b []byte) []byte`: Computes the hash and appends it to a byte slice.

* `Size() int`: Returns the size of the hash based on the specified bit size (128, 256, 384, 512).

* `BlockSize() int`: Returns the block size for the hash.

* `GetHash(data []byte) []byte`: Computes or retrieves the hash for the given data, utilizing the LRU cache.


**3. Notation**

**Step 1:** Hashing the Stretched Key
Argon2id is used to derive a stretched key from the input data and salt. The stretched key is computed as:

$$ 
stretchedKey=Argon2id(data∥salt,iterations,memory,parallelism,outputSize)
$$

  * $data∥salt$: Concatenation of input data and salt.

  * $iterations$: Number of passes over memory (set to 2).

  * $memory$: Memory cost in KiB (set to 64 KiB).

  * $parallelism$: Number of threads (set to 1).

  * $outputSize$: Size of the derived key (64 bytes).

**Step 2:** Hash Chaining

The hash function combines two cryptographic primitives:

  * SHA-512/256: A truncated version of SHA-512, producing a 256-bit hash.

  * SHAKE256: An extendable-output function (XOF) based on SHA-3, producing a variable-length hash.

The chaining operation is defined as:

$$
H_chain(x)=H_1 (x) ∥ H_2 (x)
$$

  * $H_1(x)$: SHA-512/256 hash of the input.

  * $H_2(x)$: SHAKE256 hash of the input, with length determined by the output size.


**Step 3:** Iterative Mixing

The hash undergoes multiple rounds of transformations to enhance security:

**Bit Rotation:**

$$
hash[i]=(hash[i]≪3)∨(hash[i]≫5)
$$

   * $≪$: Left bitwise rotation.

   * $∨$: Bitwise OR.

**XOR with Prime Constant:**

$$
hash[i]=hash[i]⊕(primeConstant≫(roundmod64))
$$

  * $⊕$: Bitwise XOR.

  * $primeConstant$: A 64-bit prime constant (e.g., 0x9e3779b97f4a7c15).

**Re-hashing:**

After each round, the hash is re-hashed using SHA-512/256 to ensure diffusion.

**Prime Constant Mixing:**

The hash is further mixed by adding a prime constant to each 64-bit segment:

$$
hash[i:i+8]=hash[i:i+8]+primeConstant
$$

**4. Explanation of the Goals**

The SphinxHash function aims to achieve several cryptographic goals:

* Pre-image Resistance: Making it computationally difficult to find an input 𝑥 such that 𝐻(𝑥)= ℎ where ℎ is the hash output. This ensures that even knowing the hash output doesn't allow an attacker to easily find the original data.
* Collision Resistance: Ensuring that it is difficult to find two distinct inputs $𝑥_1$ and $𝑥_2$ such that $𝐻(𝑥_1)$ = $𝐻(𝑥_2)$. This makes it hard to generate different inputs that result in the same hash value.
* Non-commutative Iterative Hashing: The iterative rounds, bitwise operations like XOR, and prime constants ensure that the hash is non-commutative. This means that even though Grover’s algorithm could speed up the search for a pre-image, the complexity of the iterative rounds and non-commutative behavior would make it impractical to exploit the speed-up.
* Diffusion and Avalanche Effect: Each round applies bit rotations and XOR with a round-specific prime constant. These operations ensure that small changes in the input data lead to large changes in the resulting hash, making it more secure against attacks like brute-force and Grover's algorithm.


**5. Explanation of Assumptions and Difficulty**
> _Imagine a maze with a single entrance and exit. A classical computer would try every path one by one to find the exit. Grover's Algorithm could potentially find the exit faster than a classical computer by exploring multiple paths simultaneously. However, the code provided adds additional twists and turns to the maze in each round. These twists are non-commutative, meaning taking a wrong turn makes it harder to retrace the steps. Even with Grover's ability to explore multiple paths, the complexity of the maze makes it difficult to efficiently find the exit (the pre-image)._

* Classical Computing: A classical computer trying to find a pre-image (i.e., the original data from the hash output) would use brute-force methods. However, with many iterations and non-commutative operations, it becomes much harder to reverse the process, akin to a maze with many twists and turns. The attacker would need to explore multiple paths, but the non-commutative nature of the rounds introduces new challenges at each step.

* Grover's Algorithm: Grover’s algorithm offers a quadratic speedup over brute force when trying to find a pre-image. However, due to the non-commutative operations and iterative rounds, the function introduces more complexity than would typically be overcome by Grover’s speedup. This can be imagined as a maze where each path taken may lead to a dead-end, and retracing steps is difficult. Each iteration of the hashing rounds adds "twists" to the maze, making it harder to efficiently find the exit (the pre-image), even with the quantum speedup provided by Grover’s algorithm.

* Twists in the Maze: The bit rotations and XOR operations with the round-specific prime constants add layers of complexity, preventing an attacker from efficiently exploiting Grover’s algorithm. Each twist introduces a new challenge, making it harder to track the path and find the exit (pre-image). The function’s multiple rounds and the final mixing step with the prime constant further increase this difficulty.


## Future improvement
We on going to replace **SHA2-256** with **[Lattice-based Hash Function](https://github.com/sphinx-core/sphinx-core/tree/main/src/crypto/Swifftx)** that will combine with **SHA3-SHAKE256** since the world did known that **Lattice** problem can resistant against well known quantum-computing algorithm.

## Conclusion

The SphinxHash function combines multiple hash outputs using structured techniques and prime constants to enhance security. It features caching to optimize performance and provides a flexible interface for hash generation across various bit sizes.

### References
[https://www.rfc-editor.org/rfc/rfc9106.html](https://www.rfc-editor.org/rfc/rfc9106.html)

[Guarding Against Cryptanalytic Breakthroughs: Combining Multiple Hash Functions](https://crypto.stackexchange.com/questions/270/guarding-against-cryptanalytic-breakthroughs-combining-multiple-hash-functions/328#328)

[Why is XOR the Default Way to Combine Hashes?](https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes)

[xor is a dangerous default function to use when hashing. It is better than and and or, but that doesn't say much](https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes)

